{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection with SSD\n",
    "\n",
    "In this example, we will load a SSD model and use it to detect objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup\n",
    "\n",
    "* First, Load necessary libs and set up caffe and caffe_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "import cv2\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Make sure that caffe is on the python path\n",
    "import os\n",
    "caffe_root = '/home/ubuntu/Amin-SSD/caffe/' #os.environ['CAFFE_ROOT']\n",
    "os.chdir(caffe_root)\n",
    "import sys\n",
    "sys.path.insert(0, 'python')\n",
    "\n",
    "import caffe\n",
    "caffe.set_device(0)\n",
    "caffe.set_mode_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load LabelMap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from google.protobuf import text_format\n",
    "from caffe.proto import caffe_pb2\n",
    "\n",
    "# load Okutama labels\n",
    "labelmap_file = 'data/okutama/labelmap_SDD_detection.prototxt'\n",
    "file = open(labelmap_file, 'r')\n",
    "labelmap = caffe_pb2.LabelMap()\n",
    "text_format.Merge(str(file.read()), labelmap)\n",
    "\n",
    "def get_labelname(labelmap, labels):\n",
    "    num_labels = len(labelmap.item)\n",
    "    labelnames = []\n",
    "    if type(labels) is not list:\n",
    "        labels = [labels]\n",
    "    for label in labels:\n",
    "        found = False\n",
    "        for i in xrange(0, num_labels):\n",
    "            if label == labelmap.item[i].label:\n",
    "                found = True\n",
    "                labelnames.append(labelmap.item[i].display_name)\n",
    "                break\n",
    "        assert found == True\n",
    "    return labelnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load the net in the test phase for inference, and configure input preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_def = 'models/VGGNet/okutama/SSD_512x512/deploy.prototxt'\n",
    "model_weights = 'models/VGGNet/okutama/SSD_512x512/VGG_okutama_SSD_512x512_iter_2000.caffemodel'\n",
    "\n",
    "net = caffe.Net(model_def,      # defines the structure of the model\n",
    "                model_weights,  # contains the trained weights\n",
    "                caffe.TEST)     # use test mode (e.g., don't perform dropout)\n",
    "\n",
    "# input preprocessing: 'data' is the name of the input blob == net.inputs[0]\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "#transformer = caffe.io.Transformer({'data': (1,3,1280,720)})\n",
    "transformer.set_transpose('data', (2, 0, 1))\n",
    "transformer.set_mean('data', np.array([104,117,123])) # mean pixel\n",
    "transformer.set_raw_scale('data', 255)  # the reference model operates on images in [0,255] range instead of [0,1]\n",
    "transformer.set_channel_swap('data', (2,1,0))  # the reference model has channels in BGR order instead of RGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SSD detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set net to batch size of 1\n",
    "image_resize = 512\n",
    "net.blobs['data'].reshape(1,3,image_resize,image_resize)\n",
    "\n",
    "image = caffe.io.load_image('/home/ubuntu/okutama17/1.2.10/images/100.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the net and examine the top_k results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transformed_image = transformer.preprocess('data', image)\n",
    "net.blobs['data'].data[...] = transformed_image\n",
    "\n",
    "# Forward pass.\n",
    "net.forward()\n",
    "detections = net.blobs['detection_out'].data\n",
    "\n",
    "# Parse the outputs.\n",
    "det_label = detections[0,0,:,1]\n",
    "det_conf = detections[0,0,:,2]\n",
    "det_xmin = detections[0,0,:,3]\n",
    "det_ymin = detections[0,0,:,4]\n",
    "det_xmax = detections[0,0,:,5]\n",
    "det_ymax = detections[0,0,:,6]\n",
    "\n",
    "# Get detections with confidence higher than .\n",
    "top_indices = [i for i, conf in enumerate(det_conf) if conf >= 0.5]\n",
    "\n",
    "top_conf = det_conf[top_indices]\n",
    "top_label_indices = det_label[top_indices].tolist()\n",
    "top_labels = get_labelname(labelmap, top_label_indices)\n",
    "top_xmin = det_xmin[top_indices]\n",
    "top_ymin = det_ymin[top_indices]\n",
    "top_xmax = det_xmax[top_indices]\n",
    "top_ymax = det_ymax[top_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot the boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colors = plt.cm.hsv(np.linspace(0, 1, 21)).tolist()\n",
    "\n",
    "my_dpi = 80\n",
    "plt.figure(figsize=(1280/my_dpi, 720/my_dpi), dpi=my_dpi)\n",
    "\n",
    "fig = plt.imshow(image)\n",
    "fig.axes.get_xaxis().set_visible(False)\n",
    "fig.axes.get_yaxis().set_visible(False)  \n",
    "plt.show()\n",
    "\n",
    "my_dpi = 80\n",
    "plt.figure(figsize=(1280/my_dpi, 720/my_dpi), dpi=my_dpi)\n",
    "\n",
    "fig = plt.imshow(image)\n",
    "currentAxis = plt.gca()\n",
    "\n",
    "for i in xrange(top_conf.shape[0]):\n",
    "    xmin = int(round(top_xmin[i] * image.shape[1]))\n",
    "    ymin = int(round(top_ymin[i] * image.shape[0]))\n",
    "    xmax = int(round(top_xmax[i] * image.shape[1]))\n",
    "    ymax = int(round(top_ymax[i] * image.shape[0]))\n",
    "    score = top_conf[i]\n",
    "    label = int(top_label_indices[i])\n",
    "    label_name = top_labels[i]\n",
    "    display_txt = '%s: %.2f'%(label_name, score)\n",
    "    coords = (xmin, ymin), xmax-xmin+1, ymax-ymin+1\n",
    "    color = colors[label]\n",
    "    currentAxis.add_patch(plt.Rectangle(*coords, fill=False, edgecolor=color, linewidth=1))\n",
    "    currentAxis.text(xmin, ymin, display_txt, bbox={'facecolor':color, 'alpha':0.4},fontsize=8)\n",
    "    \n",
    "fig.axes.get_xaxis().set_visible(False)\n",
    "fig.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.savefig('../../output/save.jpg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "colors = plt.cm.hsv(np.linspace(0, 1, 21)).tolist()\n",
    "img = cv2.imread('/home/ubuntu/okutama17/1.2.10/images/100.jpg')\n",
    "#img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "for i in xrange(top_conf.shape[0]):\n",
    "    xmin = int(round(top_xmin[i] * image.shape[1]))\n",
    "    ymin = int(round(top_ymin[i] * image.shape[0]))\n",
    "    xmax = int(round(top_xmax[i] * image.shape[1]))\n",
    "    ymax = int(round(top_ymax[i] * image.shape[0]))\n",
    "    \n",
    "    score = top_conf[i]\n",
    "    label = int(top_label_indices[i])\n",
    "    label_name = top_labels[i]\n",
    "    display_txt = '%s: %.2f'%(label_name, score)\n",
    "    coords = (xmin, ymin), xmax-xmin+1, ymax-ymin+1\n",
    "    color = colors[label]\n",
    "    \n",
    "    cv2.rectangle(img,(xmin,ymin),(xmax, ymax), color, 1)\n",
    "    cv2.putText(img, display_txt, (xmin,ymin), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0,0,0), 1)\n",
    "cv2.imwrite('../../output/test2.png', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. SSD video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load frames to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ... 0\n"
     ]
    }
   ],
   "source": [
    "model_def = 'models/VGGNet/okutama/SSD_512x512/deploy.prototxt'\n",
    "model_weights = 'models/VGGNet/okutama/SSD_512x512/VGG_okutama_SSD_512x512_iter_2000.caffemodel'\n",
    "\n",
    "net = caffe.Net(model_def,      # defines the structure of the model\n",
    "                model_weights,  # contains the trained weights\n",
    "                caffe.TEST)     # use test mode (e.g., don't perform dropout)\n",
    "\n",
    "# input preprocessing: 'data' is the name of the input blob == net.inputs[0]\n",
    "#transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "transformer = caffe.io.Transformer({'data': (1,3,512,512)})\n",
    "transformer.set_transpose('data', (2, 0, 1))\n",
    "transformer.set_mean('data', np.array([104,117,123])) # mean pixel\n",
    "transformer.set_raw_scale('data', 255)  # the reference model operates on images in [0,255] range instead of [0,1]\n",
    "transformer.set_channel_swap('data', (2,1,0))  # the reference model has channels in BGR order instead of RGB\n",
    "\n",
    "\n",
    "# set net to batch size of 1\n",
    "image_resize = 512 # Should be set\n",
    "video_id = \"1.1.8\" # Should be set\n",
    "data_set_path = \"/home/ubuntu/okutama17/\" # Should be Set\n",
    "\n",
    "save_path = '../../output/'+video_id+\"/\"\n",
    "#os.makedirs(save_path)\n",
    "start_frame=0\n",
    "end_frame= 1834 #len(os.listdir(video_path))\n",
    "#interval=1 # should be set\n",
    "threshold = 0.3  # should be set\n",
    "my_dpi = 80\n",
    "\n",
    "video_path = os.path.join(data_set_path, video_id, \"images\")\n",
    "net.blobs['data'].reshape(1,3,512,512)\n",
    "\n",
    "\n",
    "colors = plt.cm.hsv(np.linspace(0, 1, 21)).tolist()\n",
    "\n",
    "\n",
    "pt=plt.figure(figsize=(1280/my_dpi, 720/my_dpi), dpi=my_dpi)\n",
    "\n",
    "for frame in xrange(start_frame, end_frame+1):\n",
    "    if frame % 25 == 0:\n",
    "        print \"Loading ...\", frame\n",
    "    image = caffe.io.load_image(os.path.join(video_path,str(frame)+'.jpg'))\n",
    "    transformed_image = transformer.preprocess('data', image)\n",
    "    net.blobs['data'].data[...] = transformed_image\n",
    "    net.forward()\n",
    "    detections = net.blobs['detection_out'].data\n",
    "    # Parse the outputs.\n",
    "    det_label = detections[0,0,:,1]\n",
    "    det_conf = detections[0,0,:,2]\n",
    "    det_xmin = detections[0,0,:,3]\n",
    "    det_ymin = detections[0,0,:,4]\n",
    "    det_xmax = detections[0,0,:,5]\n",
    "    det_ymax = detections[0,0,:,6]\n",
    "    # Get detections with confidence higher than \n",
    "    top_indices = [i for i, conf in enumerate(det_conf) if conf >= threshold]\n",
    "\n",
    "    top_conf = det_conf[top_indices]\n",
    "    top_label_indices = det_label[top_indices].tolist()\n",
    "    top_labels = get_labelname(labelmap, top_label_indices)\n",
    "    top_xmin = det_xmin[top_indices]\n",
    "    top_ymin = det_ymin[top_indices]\n",
    "    top_xmax = det_xmax[top_indices]\n",
    "    top_ymax = det_ymax[top_indices]\n",
    "    \n",
    "    pt.clear()\n",
    "    currentAxis = pt.gca()\n",
    "    fig  = currentAxis.imshow(image)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    for i in xrange(top_conf.shape[0]):\n",
    "        xmin = int(round(top_xmin[i] * image.shape[1]))\n",
    "        ymin = int(round(top_ymin[i] * image.shape[0]))\n",
    "        xmax = int(round(top_xmax[i] * image.shape[1]))\n",
    "        ymax = int(round(top_ymax[i] * image.shape[0]))\n",
    "        score = top_conf[i]\n",
    "        label = int(top_label_indices[i])\n",
    "        label_name = top_labels[i]\n",
    "        display_txt = '%s: %.2f'%(label_name, score)\n",
    "        coords = (xmin, ymin), xmax-xmin+1, ymax-ymin+1\n",
    "        color = colors[label]\n",
    "        currentAxis.add_patch(plt.Rectangle(*coords, fill=False, edgecolor=color, linewidth=1))\n",
    "        currentAxis.text(xmin, ymin, display_txt, bbox={'facecolor':color, 'alpha':0.4},fontsize=8)\n",
    "\n",
    "    fig.axes.get_xaxis().set_visible(False)\n",
    "    fig.axes.get_yaxis().set_visible(False)\n",
    "    pt.savefig(save_path+str(frame).zfill(4)+'.jpg', bbox_inches='tight')\n",
    "    \n",
    "print \"IT'S DONE !!!\"    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
